{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomics Data Simulation to Machine Learning ready table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook is a great tool for data scientists who are working on Genomics data analysis. We will demonstrate the process of simulation of paired-end fastq files to downstream analysis ready table format with `ART, Cromwell on Azure, GATK and Picard` on Jupyter notebook.\n",
    "\n",
    "**Here is the coverage of this notebook:**\n",
    "\n",
    "**1.** Simulate Next Generation Sequencing Data with ART\n",
    "\n",
    "**2.** Convert fastq paired-end data to uBAM with Cromwell on Azure \n",
    "\n",
    "**3.** uBAM to VCF with Cromwell on Azure\n",
    " \n",
    "    3.1.Alignment and Variant Calling with Microsoft Genomics service\n",
    "\n",
    "**4.** Convert the gVCF file to a table format\n",
    "\n",
    "\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "This notebook requires the following libraries:\n",
    "\n",
    "- Azure CLI \n",
    "\n",
    "- AzCopy: Please install latest release of the `AzCopy`: https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10\n",
    "\n",
    "- Cromwell on Azure: Please download the latest release of `CoA` from: https://github.com/microsoft/CromwellOnAzure/releases\n",
    "\n",
    "- ART: ART is a set of simulation tools to generate synthetic next-generation sequencing reads. Please download the latest version of this tool from:  \n",
    "https://www.niehs.nih.gov/research/resources/software/biostatistics/art/index.cfm\n",
    "\n",
    "- Picard: Please download the latest release of the tool from https://broadinstitute.github.io/picard/\n",
    "\n",
    "- Genome Analysis Toolkit (GATK) (*Users need to download `GATK` from Broad Institute's webpage into the same compute environment with this notebook: https://github.com/broadinstitute/gatk/releases*)\n",
    "\n",
    "- Users need reference genome for using this notebook on their environment: [hg19.fasta](https://azure.microsoft.com/en-us/services/open-datasets/catalog/genomics-reference-genomes/)\n",
    "\n",
    "**Important information: This notebook is using Python 3.6 kernel**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulate Next Generation Sequencing Data with ART - **Sample Code**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We recommend to use ART ([quote from the ART's website](https://www.niehs.nih.gov/research/resources/software/biostatistics/art/index.cfm): \"_ART is a set of simulation tools to generate synthetic next-generation sequencing reads. ART simulates sequencing reads by mimicking real sequencing process with empirical error models or quality profiles summarized from large recalibrated sequencing data\"_) for NGS data simulation.\n",
    "\n",
    "This is a great tool to simulate a NGS data for different sequencing platforms. Simulated data sets are very close to the real genomics datasets. Users can test their own downstream analysis with the simulated data sets.\n",
    "\n",
    "In this notebook, we will demonstrate the 'paired sample fastq' simulation with sample codes. Please visit tool's website for further sample codes. \n",
    "\n",
    "Please download the ART binary files from this [link](https://www.niehs.nih.gov/research/resources/software/biostatistics/art/index.cfm) than just call the code in below.\n",
    "\n",
    "Based on the information on the manual of [ART](https://www.niehs.nih.gov/research/resources/software/biostatistics/art/index.cfm), parameters of the simulation are defined as follows: \n",
    "\n",
    "\n",
    "        -ss  --seqSys   The name of Illumina sequencing system of the built-in profile used for simulation\n",
    "        \n",
    "        -i   --in       the filename of input DNA/RNA reference\n",
    "        \n",
    "        -p   --paired   indicate a paired-end read simulation or to generate reads from both ends of amplicons\n",
    "                        NOTE: art will automatically switch to a mate-pair simulation if the given mean fragment size >= 2000\n",
    "                        \n",
    "        -l   --len      the length of reads to be simulated\n",
    "          \n",
    "        -f   --fcov     the fold of read coverage to be simulated or number of reads/read pairs generated for each amplicon\n",
    "                        \n",
    "        -m   --mflen    the mean size of DNA/RNA fragments for paired-end simulations\n",
    "        \n",
    "        -s   --sdev     the standard deviation of DNA/RNA fragment size for paired-end simulations.\n",
    "        \n",
    "        -o   --out      the prefix of output filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./art_illumina -ss HS25 -sam -i hg19.fasta -p -l 150 -f 20 -m 200 -s 10 -o paired_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output report of this function will be: \n",
    "\n",
    "                  Paired-end sequencing simulation\n",
    "\n",
    "    ** Parameters used during run **\n",
    "        Read Length:    150\n",
    "        Genome masking 'N' cutoff frequency:    1 in 150\n",
    "        Fold Coverage:            20X\n",
    "        Mean Fragment Length:     200\n",
    "        Standard Deviation:       10\n",
    "        Profile Type:             Combined\n",
    "        ID Tag:                   \n",
    "\n",
    "    ** Quality Profile(s) **\n",
    "        First Read:   HiSeq 2500 Length 150 R1 (built-in profile) \n",
    "        First Read:   HiSeq 2500 Length 150 R2 (built-in profile) \n",
    "\n",
    "    ** Output files **\n",
    "\n",
    "      FASTQ Sequence Files: ~ 57.7 GB\n",
    "         the 1st reads: paired_dat1.fq\n",
    "         the 2nd reads: paired_dat2.fq \n",
    "\n",
    "      ALN Alignment Files: ~ 60.4 GB\n",
    "         the 1st reads: paired_dat1.aln\n",
    "         the 2nd reads: paired_dat2.aln\n",
    "\n",
    "      SAM Alignment File: ~ 129.2 GB\n",
    "        paired_dat.sam \n",
    "\n",
    "Reference: [ART](https://www.niehs.nih.gov/research/resources/software/biostatistics/art/index.cfm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert fastq paired-end data to uBAM with Cromwell on Azure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users needs to use the [\"Sequence data format conversion pipelines on Azure\"](https://github.com/microsoft/CromwellOnAzure/blob/master/docs/example-fastq-to-ubam.md/#Example-workflow-to-convert-FASTQ-files-to-uBAM-files) for converting the simulated fastq files to uBAM files. Here is the brief information about this pipeline.\n",
    "\n",
    "### paired-fastq-to-unmapped-bam :\n",
    "This WDL converts paired FASTQ to uBAM and adds read group information \n",
    "\n",
    "#### Requirements/expectations \n",
    "- Pair-end sequencing data in FASTQ format (one file per orientation)\n",
    "- The following metada descriptors per sample: \n",
    "  - readgroup   \n",
    "  - sample_name\n",
    "  - library_name\n",
    "  - platform_unit\n",
    "  - run_date\n",
    "  - platform_name\n",
    "  - sequecing_center\n",
    "  \n",
    "#### Outputs \n",
    "- Unmapped BAM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. uBAM to gVCF with Cromwell on Azure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step on this notebooks is 'variant calling' analysis for further downstream analysis. We recommend to use 'gatk4 genome processing pipeline' for this phase. Users can use the existed pipelines from [\"gatk4-genome-processing-pipeline-azure\"](https://github.com/microsoft/gatk4-genome-processing-pipeline-azure/blob/master-azure/README.md). Here is the inputs and outputs of this pipeline.\n",
    "\n",
    "## gatk4-genome-processing-pipeline\n",
    "Workflows used for germline processing in whole genome sequence data.\n",
    "\n",
    "### WholeGenomeGermlineSingleSample :\n",
    "This WDL pipeline implements data pre-processing and initial variant calling (GVCF\n",
    "generation) according to the GATK Best Practices (June 2016) for germline SNP and\n",
    "Indel discovery in human whole-genome sequencing data.\n",
    "\n",
    "#### Requirements/expectations\n",
    "- Human whole-genome paired-end sequencing data in unmapped BAM (uBAM) format\n",
    "- One or more read groups, one per uBAM file, all belonging to a single sample (SM)\n",
    "- Input uBAM files must additionally comply with the following requirements:\n",
    "- - filenames all have the same suffix (we use \".unmapped.bam\")\n",
    "- - files must pass validation by ValidateSamFile\n",
    "- - reads are provided in query-sorted order\n",
    "- - all reads must have an RG tag\n",
    "- Reference genome must be Hg38 with ALT contigs\n",
    "\n",
    "#### Outputs \n",
    "- Cram, cram index, and cram md5 \n",
    "- GVCF and its gvcf index \n",
    "- BQSR Report\n",
    "- Several Summary Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Alignment and Variant Calling with Microsoft Genomics service- Optional\n",
    "\n",
    "Users can also use the [Microsoft Genomics service](https://azure.microsoft.com/en-us/services/genomics/) for alligment and variant calling process. The Microsoft Genomics client (msgen) is a Python front-end to the web service. It can be\n",
    "installed like a standard Python package, on Windows or Linux using the Python pip package manager (“pip install msgen”). For each genome sample that you want to process, you create a configuration file containing all the parameters for downloading the data, running the Microsoft Genomics pipeline, and uploading the results:\n",
    "\n",
    "• Your subscription key to Microsoft\n",
    "Genomics\n",
    "\n",
    "• The process to run and its parameters\n",
    "\n",
    "• Path information and storage account\n",
    "keys for the input files in either paired\n",
    "FASTQ, paired compressed FASTQ, or\n",
    "BAM format, in Azure Storage\n",
    "\n",
    "• Path information and storage account\n",
    "key for the location to place the output files in Azure Storage\n",
    "\n",
    "You can then invoke the msgen client to initiate processing, and monitor progress until the job is complete. The final aligned reads in BAM format, and variant calls in VCF.GZ format will be placed in your designated output container in Azure Storage. The client can easily be incorporated into existing workflows. Here is the sample code for calling Microsoft Genomics service from Python client.\n",
    "\n",
    "Please visit  [quick start run](https://docs.microsoft.com/en-us/azure/genomics/quickstart-run-genomics-workflow-portal) page for sample job submission to the service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./msgen submit -f ./config.txt -b1 paired_dat1.fq -b2 paired_dat2.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convert the final gVCF file to a table format -VariantsToTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optional final step before downstream analysis is converting gvcf file to a table format for specific parameters. \n",
    "\n",
    "Extract fields from a VCF file to a tab-delimited table\n",
    "This tool extracts specified fields for each variant in a VCF file to a tab-delimited table, which may be easier to work with than a VCF. By default, the tool only extracts PASS or . (unfiltered) variants in the VCF file. Filtered variants may be included in the output by adding the --show-filtered flag. The tool can extract both INFO (i.e. site-level) fields and FORMAT (i.e. sample-level) fields. \n",
    "\n",
    "Reference: [Variants to table](https://gatk.broadinstitute.org/hc/en-us/articles/360036882811-VariantsToTable)\n",
    "\n",
    "\n",
    "**INFO/site-level fields**\n",
    "\n",
    "Use the `-F` argument to extract INFO fields; each field will occupy a single column in the output file. The field can be any standard VCF column (e.g. CHROM, ID, QUAL) or any annotation name in the INFO field (e.g. AC, AF). The tool also supports the following additional fields:\n",
    "\n",
    "EVENTLENGTH (length of the event)\n",
    "TRANSITION (1 for a bi-allelic transition (SNP), 0 for bi-allelic transversion (SNP), -1 for INDELs and multi-allelics)\n",
    "HET (count of het genotypes)\n",
    "HOM-REF (count of homozygous reference genotypes)\n",
    "HOM-VAR (count of homozygous variant genotypes)\n",
    "NO-CALL (count of no-call genotypes)\n",
    "TYPE (type of variant, possible values are NO_VARIATION, SNP, MNP, INDEL, SYMBOLIC, and MIXED\n",
    "VAR (count of non-reference genotypes)\n",
    "NSAMPLES (number of samples)\n",
    "NCALLED (number of called samples)\n",
    "MULTI-ALLELIC (is this variant multi-allelic? true/false)\n",
    "\n",
    "\n",
    "**FORMAT/sample-level fields**\n",
    "\n",
    "Use the `-GF` argument to extract FORMAT/sample-level fields. The tool will create a new column per sample with the name \"SAMPLE_NAME.FORMAT_FIELD_NAME\" e.g. NA12877.GQ, NA12878.GQ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**\n",
    "\n",
    "A VCF file to convert to a table\n",
    "\n",
    "**Output**\n",
    "\n",
    "A tab-delimited file containing the values of the requested fields in the VCF file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gatk VariantsToTable -V simoutput.g.vcf.gz -F CHROM -F POS -F TYPE -F AC -F AD -F AF -GF DP -GF AD -O outputtable.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Cromwell on Azure: https://github.com/microsoft/CromwellOnAzure/releases\n",
    "\n",
    "2. ART: https://www.niehs.nih.gov/research/resources/software/biostatistics/art/index.cfm\n",
    "\n",
    "3. Variants to table: https://gatk.broadinstitute.org/hc/en-us/articles/360036882811-VariantsToTable \n",
    "\n",
    "4. Picard: https://broadinstitute.github.io/picard/ \n",
    "\n",
    "5. AzCopy: https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTICES\n",
    "\n",
    "THIS NOTEBOOK HAS JUST A SAMPLE CODES. MICROSOFT DOES NOT CLAIM ANY OWNERSHIP ON THESE CODES AND LIBRARIES. MICROSOFT PROVIDES THIS NOTEBOOK AND SAMPLE USE OF ART'S SIMULATION LIBRARIES ON AN “AS IS” BASIS. MICROSOFT MAKES NO WARRANTIES, EXPRESS OR IMPLIED, GUARANTEES OR CONDITIONS WITH RESPECT TO YOUR USE OF THIS NOTEBOOK. TO THE EXTENT PERMITTED UNDER YOUR LOCAL LAW, MICROSOFT DISCLAIMS ALL LIABILITY FOR ANY DAMAGES OR LOSSES, INCLUDING DIRECT, CONSEQUENTIAL, SPECIAL, INDIRECT, INCIDENTAL OR PUNITIVE, RESULTING FROM YOUR USE OF THIS NOTEBOOK.\n",
    "\n",
    "**END OF NOTEBOOK**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
